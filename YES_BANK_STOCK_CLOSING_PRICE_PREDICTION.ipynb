{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VED0905/Product-Dissection-Relational-Database/blob/main/YES_BANK_STOCK_CLOSING_PRICE_PREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YES BANK STOCK CLOSING PRICE PREDICTION**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "**Name**                  - VED PRAKASH SINGH  "
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Objective -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our objective is to analyze the impact of a fraou case involving on the stock price of Yes Bank, a prominant bank in the Indian financial domain.\n",
        "The data set used in the project consisted of monthly stock price of Yes Bank since its inception, including closing, starting, highest and lowest stock price."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (r2_score,\n",
        "mean_squared_error,  mean_absolute_percentage_error,\n",
        "mean_absolute_error)\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path =  \"/content/drive/MyDrive/data_YesBank_StockPrices.csv\"\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "JclrLNyM6sx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a small data set of total 185 rows and 5 columns. In this data set there are total 5 columns.\n",
        "We have no null value in the data set.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.info()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.columns.unique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Steps for EDA**\n",
        "\n",
        "A typical manual EDA process using pandas involves the following steps:\n",
        "* **Loading the Data:** Import your dataset (e.g., from a CSV or Excel file) into a pandas DataFrame using functions like pd.read_csv().\n",
        "* **Initial Inspection:** Use functions like head(), info(), and shape to get a general overview of the data's structure and contents.\n",
        "* **Data Cleaning:** Address missing values (imputation or dropping), handle duplicate entries using duplicated(), and correct data type issues.\n",
        "* **Univariate Analysis:** Analyze single columns using descriptive statistics (describe(), value_counts()) and basic visualizations (histograms, box plots using built-in pandas plotting or libraries like Matplotlib and Seaborn).\n",
        "* **Bivariate/Multivariate Analysis:** Investigate relationships between multiple variables using correlation matrices (corr()), scatter plots, and groupby operations.\n",
        "* **Gaining Insights:** Formulate hypotheses and extract meaningful insights that inform subsequent data preparation and machine learning modeling steps."
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Univariate Analysis**"
      ],
      "metadata": {
        "id": "Sd2PLlSV_-Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col = list(df.columns)\n",
        "a = df[col].plot(kind = 'box' , title = 'boxplot')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "ZEOP0eG9_8na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['Open'],kde=True)\n",
        "sns.distplot(df['High'],kde=True)\n",
        "sns.distplot(df['Low'],kde=True)\n",
        "sns.distplot(df['Close'],kde=True)\n",
        "plt.title(\"Distribution Of  Columns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qOACPYLtBLLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Bivariate Analysis**"
      ],
      "metadata": {
        "id": "fZ-6jip5BsXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (9,5))\n",
        "sns.lineplot(x = 'Date', y = 'Close', data = df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-wGb-W18BxPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns[1:-1]:\n",
        "  plt.title(f'Relationship Between {i} and Close')\n",
        "  sns.scatterplot(x = i, y = 'Close', data = df)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2TGvJX-2CpVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Multivariate Analysis**"
      ],
      "metadata": {
        "id": "Y2wc9QO7FEjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,5))\n",
        "co_re = sns.heatmap(df.corr(),annot = True)"
      ],
      "metadata": {
        "id": "pqe3x7PuFITY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will try to reduce multicolinearity using variable transformation."
      ],
      "metadata": {
        "id": "tMoW4mLjGjX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p_t = PowerTransformer(method = 'box-cox', standardize = True)\n",
        "c = df[list(df.columns)]\n",
        "df['Close']"
      ],
      "metadata": {
        "id": "4S0HkwqCGvrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The \"fit()\" step calculates necessary parameters (like mean/std) from data c, and transform() applies these transformations."
      ],
      "metadata": {
        "id": "sqC7jiIDINT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = pd.DataFrame(p_t.fit_transform(c))\n",
        "k.head()"
      ],
      "metadata": {
        "id": "eFKyBzsVIkas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.rename(columns= {0:'Open',1:'High',2:'Low',3:'Close'},inplace = True)"
      ],
      "metadata": {
        "id": "uJsSsu5gI5ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.head()"
      ],
      "metadata": {
        "id": "Bca819D8LdpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(k.corr(),annot = True)"
      ],
      "metadata": {
        "id": "9Vy5WDIdLw-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = list(k.columns)"
      ],
      "metadata": {
        "id": "JPwLnR7BMCw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = k[col].plot(kind = 'box', title = 'BoxPlot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LIzJW_WkMKdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The command \"sns.pairplot(k)\" generates a grid of plots visualizing the pairwise relationships and distributions of variables within the dataset k. This function, from the Seaborn library, is a fundamental tool for exploratory data analysis (EDA).\n",
        "\n",
        "# **Key Purpose**\n",
        "\n",
        "#The primary uses of sns.pairplot() include:\n",
        "\n",
        "**Identifying Relationships:** Quickly spotting potential correlations (positive, negative, or none) between multiple numerical variables.\n",
        "\n",
        "**Understanding Distributions:** Observing the spread and skewness of individual variables in the dataset.\n",
        "\n",
        "**Feature Selection:** Helping to determine which features might be most effective for building a machine learning model or further, more detailed analysis."
      ],
      "metadata": {
        "id": "aIAMEb-oM3g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(k)"
      ],
      "metadata": {
        "id": "ZcEH-JeDMdOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Preprocessing**"
      ],
      "metadata": {
        "id": "47qjWRIuPAdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing is the essential process of preparing and transforming raw, messy real-world data into a clean, structured, and consistent format that machine learning algorithms can effectively use. This crucial step directly impacts model performance, leading to improved accuracy, efficiency, and reliability."
      ],
      "metadata": {
        "id": "zK8atw7wPVOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k.head()"
      ],
      "metadata": {
        "id": "827funjPPEoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dependent_variable = 'Close'\n",
        "independent_variable = list(set(k.columns.tolist())-{dependent_variable})\n",
        ""
      ],
      "metadata": {
        "id": "NVc-1nCBPxbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[independent_variable].values\n",
        "\n",
        "\n",
        "y=df[dependent_variable].values"
      ],
      "metadata": {
        "id": "4wOfTsjYP1_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "OxwR_oPHP9_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Linear Regression**"
      ],
      "metadata": {
        "id": "Na8wshGGQBEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression is a fundamental supervised machine learning algorithm and statistical technique used to predict a continuous, numerical output Y based on one or more input features X.\n",
        "\n",
        "Linear regression analysis is used to predict the value of a variable based on the value of another variable. The variable you want to predict is called the dependent variable."
      ],
      "metadata": {
        "id": "roYD5TGhQovh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg=LinearRegression()\n",
        "reg.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "JyKlxrtGQAgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(x_test)\n",
        "linear_r2 = r2_score(y_pred,y_test)"
      ],
      "metadata": {
        "id": "zLZ068T8RJ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y_pred)\n",
        "plt.plot(y_test)\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3gE1ahFCRT9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**K_Nearest Neighbour**\n",
        "\n",
        "K-Nearest Neighbors (KNN) is a simple, non-parametric, lazy-learning algorithm used for both classification and regression. It predicts a new data point's value or class by identifying the '\n",
        "' closest labeled training samples (neighbors) and using a majority vote or average. It relies on distance metrics like Euclidean distance to measure similarity."
      ],
      "metadata": {
        "id": "2c5rXWTFRuGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_n_n = KNeighborsRegressor()\n",
        "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
        "model = GridSearchCV(k_n_n,params,cv=5)\n",
        "\n",
        "\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "MgFADCddSBkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.best_params_"
      ],
      "metadata": {
        "id": "8qSkhaOySTqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_n_n = KNeighborsRegressor(n_neighbors=2)\n",
        "k_n_n.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "6_heLdmxSf3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_n_n_pred = k_n_n.predict(x_test)\n",
        "\n",
        "\n",
        "r2_k_n_n = r2_score(y_test,k_n_n_pred)\n",
        "\n",
        "\n",
        "plt.plot(k_n_n_pred)\n",
        "plt.plot(y_test)\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zVwRyWS2SxSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Random Forest**\n",
        "\n",
        "\n",
        "Random Forest is a popular ensemble machine learning algorithm used for both classification and regression tasks by combining the output of multiple decision trees. It improves accuracy and reduces overfitting by training each tree on a random subset of data (bagging) and selecting random features for splits. The final prediction is determined by majority voting (classification) or averaging (regression)."
      ],
      "metadata": {
        "id": "OlgJoyHlTR5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor()\n",
        "params = {'n_estimators':[100,200,300],'criterion':['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],'max_features':['sqrt', 'log2', None]}\n",
        "rf_model = GridSearchCV(rf,params,cv=5)\n",
        "\n",
        "\n",
        "rf_model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "8o6diJ2mTYiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model.best_params_\n",
        "\n",
        "{'criterion': 'squared_error', 'max_features': None, 'n_estimators': 300}\n",
        "\n",
        "rf = RandomForestRegressor(criterion= 'friedman_mse', max_features= None, n_estimators= 300)\n",
        "\n",
        "\n",
        "rf.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "BsDtE1uQTyby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predict_ = rf.predict(x_test)\n",
        "\n",
        "\n",
        "rf_r2 = r2_score(y_test,rf_predict_)\n",
        "\n",
        "\n",
        "plt.plot(rf_predict_)\n",
        "plt.plot(y_test)\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S5FYZTrSUA2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ridge Regression**\n",
        "\n",
        "Ridge regression is a linear modeling technique that reduces overfitting and multicollinearity by adding an\n",
        " penalty (equal to the square of the magnitude of coefficients) to the cost function. By shrinking coefficient estimates toward zero, it decreases model variance while slightly increasing bias, improving generalization to new data. It is particularly effective when independent variables are highly correlated."
      ],
      "metadata": {
        "id": "FP3wVo06US_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge =Ridge()\n",
        "param = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,0.3,0.7,1,1.2,1.33,1.365,1.37,1.375,1.4,1.5,1.6,1.8,2.5,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, param, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(x_train,y_train)\n",
        "ridge_regressor.best_params_"
      ],
      "metadata": {
        "id": "9CoewW1NUYpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge =Ridge(alpha= 100)\n",
        "ridge.fit(x_train,y_train)\n",
        "y_pred_ridge = ridge.predict(x_test)\n",
        "ridge_r2 = r2_score(y_test,y_pred_ridge)\n",
        "ridge_r2"
      ],
      "metadata": {
        "id": "8kpD8Og8UrPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y_pred_ridge)\n",
        "plt.plot(y_test)\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aVljet2lU7_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lasso Regression**\n",
        "\n",
        "Lasso (Least Absolute Shrinkage and Selection Operator) regression is a linear regression technique that enhances model accuracy and interpretability by using L1 regularization to penalize the absolute size of coefficients. By shrinking less important feature coefficients to exactly zero, it performs automatic feature selection, reduces overfitting, and handles high-dimensional data efficiently."
      ],
      "metadata": {
        "id": "GMKI2rryVlMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso =Lasso()\n",
        "param = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,0.3,0.7,1,1.2,1.33,1.365,1.37,1.375,1.4,1.5,1.6,1.8,2.5,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, param, scoring='neg_mean_squared_error', cv=3)\n",
        "lasso_regressor.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "8k3Pf5u0UvSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_regressor.best_params_\n",
        "lasso =Lasso(alpha= 1.6)\n",
        "lasso.fit(x_train,y_train)\n",
        "lasso_predict = lasso.predict(x_test)\n",
        "lasso_r2 = r2_score(lasso_predict,y_test)"
      ],
      "metadata": {
        "id": "OKtzFLClV9Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lasso_predict)\n",
        "plt.plot(y_test)\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e4PaCaayWSVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Overall Summary**"
      ],
      "metadata": {
        "id": "rC8hhfGVWgy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure both lists have 5 elements\n",
        "summary = pd.DataFrame(data={\n",
        "    'model': ['linear regression', 'ridge regression', 'lasso regression', 'knn regression', 'Random Forest Regression'],\n",
        "    'r2_score': [linear_r2, ridge_r2, lasso_r2, r2_k_n_n, rf_r2]  # Added knn_r2\n",
        "})\n",
        "\n",
        "# Sorting correctly\n",
        "summary.sort_values(by=['r2_score'], ascending=False, inplace=True)\n",
        "\n",
        "# Display the result\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "o_Iiq40_X8Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. After loading the dataset, we found that there are no null values in our dataset nor any duplicate data.\n",
        "2. There are some outliers in our features however this being a very small dataset, dropping those instances will lead to loss of information.\n",
        "3. There is a high correlation between the dependent and independent variables. This is a signal that our dependent variable is highly dependent on our features and can be predicted accurately from them.\n",
        "4. We implemented several models on our dataset in order to be able to predict the closing price and found that all our models are performing remarkably well and knn regressor is the best performing model with A R2 score value of 0.993115 and scores well on all evaluation metrics."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}